# -*- coding: utf-8 -*-
"""ML Project Conventional.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qcKtPkSl1unzGwmXpPXKuDUJLPSuGme3
"""

# Import required libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import cv2
import os
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
from skimage.feature import hog
from skimage import color
from tqdm import tqdm

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

dataset_path = '/content/drive/MyDrive/Classroom/CSE 432 - Machine Learning Lab 7A/Project/Dataset'

def extract_improved_features(image_path, image_size=(224, 224)):
    """
    Enhanced feature extraction using multiple techniques
    """
    # Read and resize image
    img = cv2.imread(image_path)
    if img is None:
        raise ValueError(f"Could not read image: {image_path}")

    img = cv2.resize(img, image_size)

    # Convert to different color spaces
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)

    # 1. HOG Features with better parameters
    hog_features = hog(gray, orientations=9,
                      pixels_per_cell=(8, 8),
                      cells_per_block=(2, 2),
                      block_norm='L2-Hys')

    # 2. Color Histograms (both RGB and HSV)
    hist_hsv = cv2.calcHist([hsv], [0, 1, 2], None, [32, 32, 32],
                           [0, 180, 0, 256, 0, 256])
    hist_rgb = cv2.calcHist([img], [0, 1, 2], None, [32, 32, 32],
                           [0, 256, 0, 256, 0, 256])

    # 3. Edge Features
    edges = cv2.Canny(gray, 100, 200)
    edge_hist = cv2.calcHist([edges], [0], None, [32], [0, 256])

    # 4. Texture Features (GLCM)
    gray = np.float32(gray)
    texture_features = cv2.cornerHarris(gray, 2, 3, 0.04)
    texture_hist = cv2.calcHist([texture_features], [0], None, [32],
                               [0, texture_features.max()])

    # Combine all features
    combined_features = np.concatenate([
        hog_features,
        hist_hsv.flatten(),
        hist_rgb.flatten(),
        edge_hist.flatten(),
        texture_hist.flatten()
    ])

    return combined_features

def load_and_preprocess_data(dataset_path):
    features = []
    labels = []

    # Get all class folders
    class_folders = [f for f in os.listdir(dataset_path)
                    if os.path.isdir(os.path.join(dataset_path, f))]

    # Process each class
    for class_name in class_folders:
        class_path = os.path.join(dataset_path, class_name)
        print(f"Processing {class_name}...")

        # Get all images in the class folder
        image_files = [f for f in os.listdir(class_path)
                      if f.lower().endswith(('.png', '.jpg', '.jpeg'))]

        # Process each image with progress bar
        for image_name in tqdm(image_files, desc=f"Processing {class_name}"):
            image_path = os.path.join(class_path, image_name)
            try:
                image_features = extract_improved_features(image_path)
                features.append(image_features)
                labels.append(class_name)
            except Exception as e:
                print(f"Error processing {image_path}: {str(e)}")

    return np.array(features), np.array(labels)

print("Loading and preprocessing dataset...")
X, y = load_and_preprocess_data(dataset_path)

# Scale the features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Encode labels
le = LabelEncoder()
y_encoded = le.fit_transform(y)

# Split the dataset
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded
)

# Train Random Forest classifier
print("Training Random Forest classifier...")
rf_classifier = RandomForestClassifier(
    n_estimators=200,
    max_depth=20,
    min_samples_split=5,
    min_samples_leaf=2,
    n_jobs=-1,
    random_state=42
)
rf_classifier.fit(X_train, y_train)

# Make predictions
y_pred = rf_classifier.predict(X_test)

# Evaluate the model
print("\nClassification Report:")
print(classification_report(y_test, y_pred, target_names=le.classes_))

# Plot confusion matrix
plt.figure(figsize=(12, 8))
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=le.classes_, yticklabels=le.classes_)
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.tight_layout()
plt.show()

# Function to predict new images
def predict_vehicle(image_path, model, scaler, label_encoder):
    # Extract features from the new image
    features = extract_improved_features(image_path)

    # Scale features
    features_scaled = scaler.transform(features.reshape(1, -1))

    # Make prediction
    prediction = model.predict(features_scaled)
    prediction_proba = model.predict_proba(features_scaled)

    # Get the predicted class name and confidence
    predicted_class = label_encoder.inverse_transform(prediction)[0]
    confidence = np.max(prediction_proba) * 100

    return predicted_class, confidence

# Feature importance visualization
def plot_feature_importance(model, n_top=20):
    importances = model.feature_importances_
    indices = np.argsort(importances)[::-1][:n_top]

    plt.figure(figsize=(10, 6))
    plt.title('Top Feature Importances')
    plt.bar(range(n_top), importances[indices])
    plt.xticks(range(n_top), indices, rotation=45)
    plt.tight_layout()
    plt.show()

# Plot feature importance
plot_feature_importance(rf_classifier)

from google.colab import files

def test_uploaded_image():
    # Upload an image
    uploaded = files.upload()

    for filename in uploaded.keys():
        # Save the uploaded image temporarily
        image_path = filename
        with open(image_path, 'wb') as f:
            f.write(uploaded[filename])

        # Make prediction
        predicted_class, confidence = predict_vehicle(image_path, rf_classifier, scaler, le)

        # Display image and prediction
        plt.figure(figsize=(8, 6))
        img = cv2.imread(image_path)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        plt.imshow(img)
        plt.title(f'Predicted: {predicted_class}\nConfidence: {confidence:.2f}%')
        plt.axis('off')
        plt.show()

        # Clean up
        os.remove(image_path)

# Test with uploaded image
print("Upload an image to test:")
test_uploaded_image()